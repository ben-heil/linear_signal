"""This script normalizes the data from recount3"""

import argparse
from typing import Dict

import numpy as np


def parse_gene_lengths(file_path: str) -> Dict[str, int]:
    """Parses a tsv file containing genes and their length

    Arguments
    ---------
    file_path - The path to the file mapping genes to lengths

    Returns
    -------
    gene_to_len - A dict mapping ensembl gene ids to their lenght in base pairs
    """
    gene_to_len = {}
    with open(file_path) as in_file:
        # Throw out header
        in_file.readline()
        for line in in_file:
            line = line.replace('"', '')
            gene, length = line.strip().split('\t')
            try:
                gene_to_len[gene] = int(length)
            except ValueError:
                # Some genes have no length, but will be removed in a later step
                pass
    return gene_to_len


if __name__ == '__main__':
    parser = argparse.ArgumentParser()

    parser.add_argument('count_file', help='The file containing the count matrix generated by '
                                           'download_recount3.R')
    parser.add_argument('gene_file', help='The file with gene lengths from get_gene_lengths.R')
    parser.add_argument('out_file', help='The file to save the normalized results to')

    args = parser.parse_args()

    out_file = open(args.out_file, 'w')

    gene_to_len = parse_gene_lengths(args.gene_file)

    with open(args.count_file, 'r') as count_file:
        header = count_file.readline()
        header = header.replace('"', '')
        header_genes = header.strip().split('\t')
        header_genes = [gene.split('.')[0] for gene in header_genes]

        bad_indices = []
        gene_length_arr = []
        for i, gene in enumerate(header_genes):
            if gene not in gene_to_len.keys():
                bad_indices.append(i)
            else:
                gene_length_arr.append(gene_to_len[gene])

        gene_length_arr = np.array(gene_length_arr)

        header = 'study\t' + header

        # Header already contains newline
        out_file.write(header)

        for i, line in enumerate(count_file):
            line = line.replace('"', '')
            line = line.strip().split('\t')
            sample = line[0]
            try:
                # Thanks to stackoverflow for this smart optimization
                # https://stackoverflow.com/a/11303234/10930590
                counts = line[1:]  # bad_indices is still correct because of how R saves tables
                for index in reversed(bad_indices):
                    del counts[index]

                counts = np.array(counts, dtype=float)

                if any(np.isnan(counts)):
                    continue

                reads_per_kb = counts / gene_length_arr

                sample_total_counts = np.sum(counts)
                per_million_transcripts = sample_total_counts / 1e6

                tpm = reads_per_kb / per_million_transcripts

                tpm_list = tpm.tolist()
                tpm_strings = ['{}'.format(x) for x in tpm_list]

                # TODO figure out how to normalize data.
                # https://stackoverflow.com/a/15638726/10930590 may help

                out_file.write('{}\t'.format(sample))
                out_file.write('\t'.join(tpm_strings))
                out_file.write('\n')

            except ValueError as e:
                # Throw out malformed lines caused by issues with downloading data
                print(e)
